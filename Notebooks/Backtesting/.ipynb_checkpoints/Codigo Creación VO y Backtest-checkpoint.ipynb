{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando variables Campañas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para validar cruces y crear la variable respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_profiling\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil.relativedelta\n",
    "import gc\n",
    "\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def spark_read_parquet(s3_url: str, **args):\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    # Leyendo base\n",
    "    dataset = pq.ParquetDataset(s3_url, filesystem=fs)\n",
    "    table = dataset.read()\n",
    "    dataframe = table.to_pandas()\n",
    "\n",
    "    del dataset, table\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def list_files(s3_path):\n",
    "    \"\"\"\n",
    "    Función para listar los archivos de un folder en s3\n",
    "    :param s3_path: Ruta en S3 en la cual se quiere ver\n",
    "                    los archivos disponibles\n",
    "    :return: Lista de archivos encontrados\n",
    "    \"\"\"\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    bucket = s3_path.split(\"//\")[1].split(\"/\")[0]\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    prefix = \"/\".join(s3_path.split(\"//\")[1].split(\"/\")[1:])\n",
    "    list_obj = []\n",
    "    for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "        obj_x = object_summary.key.replace(prefix + \"/\", \"\").split(\"/\")[0]\n",
    "        cond_1 = not any([x == obj_x for x in list_obj])\n",
    "        cond_2 = not (object_summary.key[-9:] == \"_$folder$\")\n",
    "        if cond_1 & cond_2:\n",
    "            list_obj.append(obj_x)\n",
    "    list_obj = [x for x in list_obj if not x == prefix]\n",
    "    list_obj = [x for x in list_obj if not x == \"\"]\n",
    "    return list_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mf = r's3://data-bpop-dev-sandbox/estandarizado/transacciones/tarjeta-credito-masterfile'\n",
    "\n",
    "def trx_masterfile(fecha):\n",
    "    \"\"\"\n",
    "    Descripcion; Función para hacer tratamiento masterfile para una única tabla\n",
    "    Parámetros: fecha (numérico) en formato yyyymm\n",
    "    Retorno: data masterfile con el tratamiento adecuado de una sóla tabla\n",
    "    ejemplo: trx_masterfile(202006)\n",
    "    \"\"\"\n",
    "    #fecha = 202108\n",
    "    day = \"01\"\n",
    "    fecha_hoy = str(fecha) + day\n",
    "    fecha_total = int(fecha_hoy)  ###Con este valor se realiza la busqueda sobre las tablas acumuladas\n",
    "    ##A continuacion, se detallan algunas fechas\n",
    "    start = datetime.strptime(str(fecha_hoy), '%Y%m%d').strftime('%m/%d/%Y')\n",
    "    start = datetime.strptime(start, \"%m/%d/%Y\")\n",
    "    ##Para obtener la ficha inicial y la fecha final dia 1 y dia final del mes\n",
    "    fecha_inicial = start\n",
    "    fecha_final = start + timedelta(days=35)  ##un mes despues\n",
    "    fecha_final = fecha_final - timedelta(days=fecha_final.day)\n",
    "    ##Para convrtir en formato fecha\n",
    "    fecha_inicial = fecha_inicial.strftime('%Y%m%d')\n",
    "    fecha_final = fecha_final.strftime('%Y%m%d')\n",
    "    ##A cotninuación, se define el nombre de la tabla\n",
    "    ##Información importante: !!!!\n",
    "    ## Dado que aún no se encuentra estandarizado los datos, entonces, se define el nombre de las tablas\n",
    "    ## de la siguiente forma:\n",
    "\n",
    "    if (fecha_total >= 20201001):\n",
    "        file = 'transacciones_tarjeta-credito-masterfile_masterfile_M' + str(fecha)\n",
    "    else:\n",
    "        if (fecha_total >= 20200701 and fecha_total <= 20200930):\n",
    "            file = \"transacciones_tarjeta-credito-masterfile_masterfile_H20200701-20200930\"\n",
    "        else:\n",
    "            if (fecha_total >= 20200101 and fecha_total <= 20200630):\n",
    "                file = \"transacciones_tarjeta-credito-masterfile_masterfile_H20200101-20200630\"\n",
    "            else:\n",
    "                if (fecha_total >= 20190701 and fecha_total <= 20191231):\n",
    "                    file = \"transacciones_tarjeta-credito-masterfile_masterfile_H20190701-20191231\"\n",
    "                else:\n",
    "                    if (fecha_total >= 20190101 and fecha_total <= 20190630):\n",
    "                        file = \"transacciones_tarjeta-credito-masterfile_masterfile_H20190101-20190630\"\n",
    "                    else:\n",
    "                        file = \"transacciones_tarjeta-credito-masterfile_masterfile_H20180701-20181231\"\n",
    "    ##Para determinar la ruta fuente de la tabla transaccional\n",
    "\n",
    "    path = path_mf\n",
    "    #list_files(path)\n",
    "    #Para definir al ruta completa\n",
    "\n",
    "    #A continuación,se construye una función que determina si la tabla existe para la fecha dada\n",
    "    if file in list_files(path):\n",
    "        print(\"Si existe la data trx masterfile para la fecha \" + str(fecha))\n",
    "        ##A continuación, se realiza una lectura de la data transaccional repgesco\n",
    "        data = spark_read_parquet(path + '/' + file)\n",
    "        # data.show()\n",
    "        # vector_columns = data.columns\n",
    "        # len(vector_columns)\n",
    "        # data.count()\n",
    "        ##Para seleccionar únicamente las transacciones asociadas a compras y avances\n",
    "        ##Para seleccionar únicamente las transacciones asociadas a compras y avances\n",
    "        vector = ['2021', '2043', '5002', '5006', '5013', '5015',\n",
    "                  '5022', '8001', '8003', '8004', '8006', '8007',\n",
    "                  '8008', '8109', '2332', '2321', '2362', '8511',\n",
    "                  '8509', '8511', '2024', '2025', '2026', '2041',\n",
    "                  '2324', '2334', '2363', '5075', '2333', '2328',\n",
    "                  '8011', '8017']\n",
    "        data = data[data.cod_unico_trx.isin(vector)]\n",
    "        data.columns = data.columns.str.upper()\n",
    "        data[\"FECHA_COMPROBANTE\"] = data[\"FECHA_PROCESO\"]\n",
    "        old_names = ['TIPO_ID',\n",
    "                     'IDENTIFICACION_CLIENTE',\n",
    "                     'NRO_CUENTA',\n",
    "                     'NUMERO_TARJETA',\n",
    "                     'COD_UNICO_TRX',\n",
    "                     'FECHA_COMPROBANTE',\n",
    "                     'VALOR_TOTAL',\n",
    "                     'NOMBRE_COMERCIO',\n",
    "                     'CIUDAD_COMERCIO',\n",
    "                     'FECHA_TRANSACCION',\n",
    "                     'COD_MONEDA_ORIGEN',\n",
    "                     'CUOTAS',\n",
    "                     'FECHA_PROCESO',\n",
    "                     'MCC',\n",
    "                     'BIN']\n",
    "        data = data[old_names]\n",
    "        ##A continuación, se realiza el cambio de nombre de variables\n",
    "        new_names = ['TIPO_ID',\n",
    "                     'IDENTIFICACION_CLIENTE',\n",
    "                     'NRO_CUENTA',\n",
    "                     'NUMERO_TARJETA',\n",
    "                     'COD_TRX',\n",
    "                     'FECHA_COMPROBANTE',\n",
    "                     'VALOR_TOTAL',\n",
    "                     'NOMBRE_COMERCIO',\n",
    "                     'CIUDAD_COMERCIO',\n",
    "                     'FECHA_TRANSACCION',\n",
    "                     'COD_MONEDA_ORIGEN',\n",
    "                     'CUOTAS',\n",
    "                     'FECHA_PROCESO',\n",
    "                     'MCC',\n",
    "                     'BIN']\n",
    "        mapping = dict(zip(old_names, new_names))\n",
    "        data = data.rename(columns=mapping)\n",
    "        ##Para construir la variable tipo de TC\n",
    "        data[\"Tipo_TC\"] = np.where(data[\"BIN\"] == 474638, \"Express\",\n",
    "                               np.where(data[\"BIN\"] == 434761, \"La 14\",\n",
    "                               np.where(data[\"BIN\"] == 409648, \"La 14\",\n",
    "                               np.where(data[\"BIN\"] == 409649, \"La 14\",\n",
    "                               \"Tradicional\"))))\n",
    "        ##Seleccionar únicamente tarjetas de crédito tradicional\n",
    "        data = data[data[\"Tipo_TC\"] == \"Tradicional\"]\n",
    "        ##Para no seleccionar las tarjetas de creditos empresariales\n",
    "        data = data[data[\"BIN\"] != 454476]\n",
    "        ##Para seleccionar las variables importantes\n",
    "        variables_importantes = ['TIPO_ID',\n",
    "                                 'IDENTIFICACION_CLIENTE',\n",
    "                                 'NRO_CUENTA',\n",
    "                                 'NUMERO_TARJETA',\n",
    "                                 'FECHA_TRANSACCION',\n",
    "                                 'VALOR_TOTAL',\n",
    "                                 'NOMBRE_COMERCIO',\n",
    "                                 'CUOTAS',\n",
    "                                 'Tipo_TC',\n",
    "                                 \"MCC\"]\n",
    "        data = data[variables_importantes]\n",
    "        data['FECHA_TRANSACCION'] = pd.to_datetime(data['FECHA_TRANSACCION'], format='%Y-%m-%d')\n",
    "        ##Para seleccionar las transacciones asociadas al mes de interés\n",
    "        fecha_inicial = fecha_inicial[0:4] + \"-\" + fecha_inicial[4:6] + \"-\" + fecha_inicial[6:9] + \" 00:00:00\"\n",
    "        fecha_final = fecha_final[0:4] + \"-\" + fecha_final[4:6] + \"-\" + fecha_final[6:9] + \" 00:00:00\"\n",
    "        data = data[(data['FECHA_TRANSACCION'] >= fecha_inicial) & (data['FECHA_TRANSACCION'] <= fecha_final)]\n",
    "        data[\"periodo\"] = fecha\n",
    "        data.columns = data.columns.str.lower()\n",
    "        data = data.drop_duplicates()\n",
    "        # data.show()\n",
    "        # express_la_14 = data.filter(col(\"Tipo_TC\") != \"Tradicional\")\n",
    "        # express_la_14.show()\n",
    "        # express_la_14.count()\n",
    "        # data.count()\n",
    "        print(\"Se ha realizado el correcto tratamiento de la data masterfile periodo \" + str(fecha))\n",
    "        # data.show()\n",
    "    else:\n",
    "        print(\"No existe la data trx masterfile para la fecha \" + str(fecha))\n",
    "        data = []\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_activa(base,date,n_mes,nom_col):\n",
    "    if len(base)>0:\n",
    "        date_fin = date + relativedelta(months=n_mes)\n",
    "\n",
    "        data_act_temp = data_act.loc[(data_act['mes_activacion']>=date) & (data_act['mes_activacion']<=date_fin),['cedula','numero_cuenta','fecha_activacion','mes_activacion']].drop_duplicates()\n",
    "        ids_mes = data_act_temp['cedula'].unique()\n",
    "        \n",
    "        base.loc[base['cedula'].isin(ids_mes),'venta'] = 1    \n",
    "        base.loc[base['venta'].isnull(),'venta'] = 0\n",
    "        \n",
    "        base.loc[:,nom_col] = 1   \n",
    "        #base = pd.merge(base,data_act_temp,on=['cedula','ID_CLIENTE'],how='left')\n",
    "        base = pd.merge(base,data_act_temp,on=['cedula'],how='left')\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando bases de campañas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oficinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _key_files__list(client, bucket, key):\n",
    "    \"\"\"return the key's size if it exist, else None\"\"\"\n",
    "    response = client.list_objects_v2(Bucket=bucket, Prefix=key)\n",
    "    return response.get(\"Contents\", [])\n",
    "\n",
    "def get_s3_files(s3_url):\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\"s3\")\n",
    "    bucket = s3_url.split(\"/\")[2]\n",
    "    key = s3_url.split(\"/\")[3:]\n",
    "    key = \"/\".join(key)\n",
    "    objects = _key_files__list(s3, bucket, key)\n",
    "    files = [\"s3://\" + bucket + \"/\" + file[\"Key\"] for file in objects]\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_s3_parquet(s3_url, flag):\n",
    "    \"\"\"\n",
    "    s3_url: path donde se desea buscar\n",
    "    flag: permite identificar por cual camino entrar: 1: buscar archivo especifico, 0: buscar carpeta, ejemplo las std\n",
    "    \"\"\"\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\"s3\")\n",
    "    bucket = s3_url.split(\"/\")[2]\n",
    "    print('bucket_last_file: ', bucket)\n",
    "    key = s3_url.split(\"/\")[3:]\n",
    "    key = \"/\".join(key)\n",
    "    print('key_last_file: ', key)\n",
    "#     if flag == \"1\":\n",
    "#         objects = _key_files__list(s3, bucket, key)\n",
    "#         #files = [\"s3://\" + bucket + \"/\" + file[\"Key\"] for file in objects]\n",
    "#         files = [\"s3://\" + bucket + \"/\" + file[\"Key\"][:-9] for file in objects if\n",
    "#                  file[\"Key\"].split(\"/\")[-1] == \"_SUCCESS\"]\n",
    "#     elif flag == \"0\":\n",
    "#         objects = _key_files__list(s3, bucket, key)\n",
    "#         files = [\"s3://\" + bucket + \"/\" + file[\"Prefix\"] for file in objects]\n",
    "#     else:\n",
    "#         files = []\n",
    "    files = _key_files__list(s3, bucket, key)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 's3://data-bpop-dev-refined/gestion-campanas/preaprobado-tc/'\n",
    "bucket = 'data-bpop-dev-refined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket_last_file:  data-bpop-dev-refined\n",
      "key_last_file:  gestion-campanas/preaprobado-tc/\n"
     ]
    }
   ],
   "source": [
    "objects = get_s3_parquet(path,0)\n",
    "files = [\"s3://\" + bucket + \"/\" + file[\"Key\"] for file in objects]\n",
    "\n",
    "path_file = files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = pd.read_csv(path_file, sep='|', dtype={'ID_CLIENTE':str,'NUM_DOC':str}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>act_date</th>\n",
       "      <th>base_name</th>\n",
       "      <th>clientid</th>\n",
       "      <th>office_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>20200630</td>\n",
       "      <td>CALL_ATENTO_20200702.csv</td>\n",
       "      <td>10002878</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>20200630</td>\n",
       "      <td>CALL_ATENTO_20200702.csv</td>\n",
       "      <td>10002898</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>20200630</td>\n",
       "      <td>CALL_ATENTO_20200702.csv</td>\n",
       "      <td>10009775</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>20200630</td>\n",
       "      <td>CALL_ATENTO_20200702.csv</td>\n",
       "      <td>10012869</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>20200630</td>\n",
       "      <td>CALL_ATENTO_20200702.csv</td>\n",
       "      <td>10020225</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  act_date                 base_name  clientid  office_code\n",
       "0  2020-07-03  20200630  CALL_ATENTO_20200702.csv  10002878          470\n",
       "1  2020-07-03  20200630  CALL_ATENTO_20200702.csv  10002898          660\n",
       "2  2020-07-03  20200630  CALL_ATENTO_20200702.csv  10009775          470\n",
       "3  2020-07-03  20200630  CALL_ATENTO_20200702.csv  10012869          470\n",
       "4  2020-07-03  20200630  CALL_ATENTO_20200702.csv  10020225          470"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>act_date</th>\n",
       "      <th>base_name</th>\n",
       "      <th>clientid</th>\n",
       "      <th>office_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278861</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>20220201</td>\n",
       "      <td>OFICINA_BOGOTA_20220202.csv</td>\n",
       "      <td>9514630</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278862</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>20220201</td>\n",
       "      <td>OFICINA_BOGOTA_20220202.csv</td>\n",
       "      <td>9530597</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278863</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>20220201</td>\n",
       "      <td>OFICINA_BOGOTA_20220202.csv</td>\n",
       "      <td>9651735</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278864</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>20220201</td>\n",
       "      <td>OFICINA_BOGOTA_20220202.csv</td>\n",
       "      <td>9653868</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278865</th>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>20220201</td>\n",
       "      <td>OFICINA_BOGOTA_20220202.csv</td>\n",
       "      <td>9778378</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  act_date                    base_name  clientid  \\\n",
       "278861  2022-02-03  20220201  OFICINA_BOGOTA_20220202.csv   9514630   \n",
       "278862  2022-02-03  20220201  OFICINA_BOGOTA_20220202.csv   9530597   \n",
       "278863  2022-02-03  20220201  OFICINA_BOGOTA_20220202.csv   9651735   \n",
       "278864  2022-02-03  20220201  OFICINA_BOGOTA_20220202.csv   9653868   \n",
       "278865  2022-02-03  20220201  OFICINA_BOGOTA_20220202.csv   9778378   \n",
       "\n",
       "        office_code  \n",
       "278861          270  \n",
       "278862          270  \n",
       "278863          270  \n",
       "278864           88  \n",
       "278865          460  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278866, 5)\n",
      "(237134, 3)\n"
     ]
    }
   ],
   "source": [
    "data_temp = data_temp.sort_values(['base_name','date','clientid'])\n",
    "print(data_temp.shape)\n",
    "data_temp = data_temp.groupby(['clientid','base_name']).first()\n",
    "print(data_temp.shape)\n",
    "data_temp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jupyter/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## Filtrar express-la14\n",
    "\n",
    "data_temp = data_temp.loc[~data_temp['base_name'].str.contains('EXPRES_LA14')]\n",
    "data_temp = data_temp.rename(columns={'clientid':'NUM_DOC'})\n",
    "\n",
    "## Separando:\n",
    "## Oficinas\n",
    "\n",
    "data_crm = data_temp.loc[~data_temp['base_name'].str.contains('OFICINA_BOGOTA')]\n",
    "## tipo campaña\n",
    "data_crm['TIPO CAMPAÑA'] = 'Preaprobados'\n",
    "data_crm['tipo_camp'] = 'of-preaprobados'\n",
    "# Casting variables\n",
    "data_crm['FECHA'] = pd.to_datetime(data_crm['date'],format='%Y-%m-%d')\n",
    "data_crm['mes_campaña'] = pd.to_datetime(np.where(data_crm['FECHA'].dt.day>=25, \n",
    "                                                              data_crm['FECHA']+timedelta(days=10),\n",
    "                                                              data_crm['FECHA']),format='%Y-%m-%d')\n",
    "data_crm['mes_campaña2'] = pd.to_datetime(data_crm['FECHA'].dt.strftime('%Y-%m'),format='%Y-%m')\n",
    "data_crm['mes_campaña'] = pd.to_datetime(data_crm['mes_campaña'].dt.strftime('%Y-%m'),format='%Y-%m')\n",
    "data_crm1 = data_crm.copy()\n",
    "\n",
    "## Atento\n",
    "\n",
    "data_vend = data_temp.loc[~data_temp['base_name'].str.contains('CALL_ATENTO')]\n",
    "# Casting variables\n",
    "data_vend['TIPO CAMPAÑA'] = 'Preaprobados'\n",
    "data_vend['tipo_camp'] = 'at-preaprobados'\n",
    "data_vend['FECHA'] = pd.to_datetime(data_vend['date'],format='%Y-%m-%d')\n",
    "data_vend['mes_campaña'] = pd.to_datetime(data_vend['FECHA'].dt.strftime('%Y-%m'),format='%Y-%m')\n",
    "data_vend1 = data_vend.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ya no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths = {'crm':[\n",
    "#                       's3://data-bpop-dev-sandbox/landing/tmp/tmpg_campanas-tc-nuevas-proc-crm_M202103.csv',\n",
    "#                      's3://data-bpop-dev-sandbox/landing/tmp/tmpg_campanas-tc-nuevas-proc-crm_H20200801-20210201.csv',\n",
    "                       's3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-crm/campanas-tc-nuevas-proc-crm_H20200228-20200601.csv',\n",
    "                      's3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-crm/campanas-tc-nuevas-proc-crm_H20190801-20200201.csv',\n",
    "                      's3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-crm/campanas-tc-nuevas-proc-crm_H20190104-20190702.csv'\n",
    "                    ],\n",
    "               'vendors':[\n",
    "#                         's3://data-bpop-dev-sandbox/landing/tmp/tmpg_campanas-tc-nuevas-proc-vendors_H20201201-20210301.csv',\n",
    "#                         's3://data-bpop-dev-sandbox/landing/tmp/tmpg_campanas-tc-nuevas-proc-vendors_H20200801-20210101.csv',\n",
    "                          's3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-vend/campanas-tc-nuevas-proc-vendors_H20200401-20200601.csv',\n",
    "                         's3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-vend/campanas-tc-nuevas-proc-vendors_H20190101-20200301.csv'\n",
    "                ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-crm/campanas-tc-nuevas-proc-crm_H20200228-20200601.csv\n",
      "File: s3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-crm/campanas-tc-nuevas-proc-crm_H20190801-20200201.csv\n",
      "File: s3://adl-refined-dev-popular/data_orig/campanas/tc-nuevas-proc-crm/campanas-tc-nuevas-proc-crm_H20190104-20190702.csv\n"
     ]
    }
   ],
   "source": [
    "obj = 'crm'\n",
    "\n",
    "files = input_paths[obj]\n",
    "\n",
    "for ix, file in enumerate(files):\n",
    "    print('File:', file)\n",
    "    \n",
    "    data_temp = pd.read_csv(file, sep='|', dtype={'ID_CLIENTE':str,'NUM_DOC':str}) \n",
    "    \n",
    "    if ix == 0:\n",
    "        data_crm = data_temp\n",
    "    else:\n",
    "        data_crm = pd.concat([data_crm,data_temp], ignore_index=True)\n",
    "        \n",
    "    del data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM_DOC</th>\n",
       "      <th>ID_CLIENTE</th>\n",
       "      <th>FECHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11331659</td>\n",
       "      <td>728652315426013901</td>\n",
       "      <td>28/02/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20287021</td>\n",
       "      <td>971552296816188702</td>\n",
       "      <td>28/02/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32445739</td>\n",
       "      <td>227552309591472601</td>\n",
       "      <td>28/02/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2999236</td>\n",
       "      <td>122252294553987002</td>\n",
       "      <td>28/02/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5710110</td>\n",
       "      <td>758052310452202501</td>\n",
       "      <td>28/02/2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NUM_DOC          ID_CLIENTE       FECHA\n",
       "0  11331659  728652315426013901  28/02/2020\n",
       "1  20287021  971552296816188702  28/02/2020\n",
       "2  32445739  227552309591472601  28/02/2020\n",
       "3   2999236  122252294553987002  28/02/2020\n",
       "4   5710110  758052310452202501  28/02/2020"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_crm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tipo campaña\n",
    "data_crm['TIPO CAMPAÑA'] = 'Preaprobados'\n",
    "data_crm['tipo_camp'] = 'of-preaprobados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting variables\n",
    "data_crm['FECHA'] = pd.to_datetime(data_crm['FECHA'],format='%d/%m/%Y')\n",
    "data_crm['mes_campaña'] = pd.to_datetime(np.where(data_crm['FECHA'].dt.day>=28, \n",
    "                                                              data_crm['FECHA']+timedelta(days=10),\n",
    "                                                              data_crm['FECHA']),format='%Y-%m-%d')\n",
    "data_crm['mes_campaña2'] = pd.to_datetime(data_crm['FECHA'].dt.strftime('%Y-%m'),format='%Y-%m')\n",
    "data_crm['mes_campaña'] = pd.to_datetime(data_crm['mes_campaña'].dt.strftime('%Y-%m'),format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crm = pd.concat([data_crm1,data_crm], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 'vendors'\n",
    "\n",
    "files = input_paths[obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 'vendors'\n",
    "\n",
    "files = input_paths[obj]\n",
    "\n",
    "for ix, file in enumerate(files):\n",
    "    print('File:', file)\n",
    "    \n",
    "    data_temp = pd.read_csv(file, sep='|', encoding='ISO8859-1',quoting=1, dtype={'ID_CLIENTE':str,'NUM_DOC':str})\n",
    "    if ix == 0:\n",
    "        data_vend = data_temp.copy()\n",
    "    else:\n",
    "        data_vend = pd.concat([data_vend,data_temp], ignore_index=True)\n",
    "        \n",
    "    del data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vend['TIPO CAMPAÑA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting variables\n",
    "data_vend['tipo_camp'] = np.where(data_vend['TIPO CAMPAÑA'] == 'Preaprobados','at-preaprobados','at-perfilados')\n",
    "data_vend['FECHA'] = pd.to_datetime(data_vend['FECHA'], format='%d/%m/%Y')\n",
    "data_vend['mes_campaña'] = pd.to_datetime(data_vend['FECHA'].dt.strftime('%Y-%m'),format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vend = pd.concat([data_vend1,data_vend], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniendo bases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['NUM_DOC', 'FECHA', 'mes_campaña', 'TIPO CAMPAÑA', 'tipo_camp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vend.columns = data_vend.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_camp = pd.concat([data_crm[cols1], data_vend[cols2]], ignore_index=True)[cols2]\n",
    "data_camp = pd.concat([data_crm[cols], data_vend[cols]], ignore_index=True)[cols]\n",
    "print(data_camp.shape)\n",
    "data_camp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_camp['NUM_DOC'] = data_camp['NUM_DOC'].astype(np.int64)\n",
    "data_camp['FECHA'] = pd.to_datetime(data_camp['FECHA'])\n",
    "data_camp['mes_campaña'] = pd.to_datetime(data_camp['mes_campaña'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_camp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conteos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_camp['mes_campaña'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data_vend['mes_campaña'] ,data_vend['TIPO CAMPAÑA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data_crm['mes_campaña'] ,data_crm['TIPO CAMPAÑA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_act = ['s3://adl-refined-dev-popular/data_orig/productos/activo-tarjeta-credito-activadas/productos_activos-tarjeta-credito-activadas_H202003-202005.csv',\n",
    "            's3://adl-refined-dev-popular/data_orig/productos/activo-tarjeta-credito-activadas/productos_activos-tarjeta-credito-activadas_H20180101-20200327.csv'\n",
    "           ]\n",
    "path = 's3://data-bpop-dev-sandbox/estandarizado/productos/activo-tarjeta-credito-nueva/Productos_Activo-Tarjeta-credito-nueva_Masterfile_D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act2 = pd.read_csv(path_act[0], sep = '|', dtype={'ID_CLIENTE':str,'Numero_cuenta':str,'Identificacion':str})\n",
    "data_act2 = data_act2.drop_duplicates()\n",
    "\n",
    "print(data_act2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act1 = pd.read_csv(path_act[1], sep = '|', dtype={'ID_CLIENTE':str,'Numero_cuenta':str,'Identificacion':str})\n",
    "data_act1 = data_act1.drop_duplicates()\n",
    "\n",
    "print(data_act1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniendo bases\n",
    "data_act2['fecha_activacion'] = data_act2['fecha_activacion'].str.replace('/20','/2020')\n",
    "data_act1 = pd.concat([data_act2, data_act1], ignore_index=True)\n",
    "\n",
    "# Casting variables\n",
    "data_act1['fecha_activacion'] = pd.to_datetime(data_act1['fecha_activacion'],format='%d/%m/%Y')\n",
    "data_act1['mes_activacion'] = pd.to_datetime(data_act1['fecha_activacion'].dt.strftime('%Y-%m'),format='%Y-%m')\n",
    "\n",
    "del data_act2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act1.columns = data_act1.columns.str.lower()\n",
    "data_act1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import boto3.session\n",
    "\n",
    "def _key_existing_size__list(client, bucket, key):\n",
    "    \"\"\"return the key's size if it exist, else None\"\"\"\n",
    "    response = client.list_objects_v2(Bucket=bucket, Prefix=key)\n",
    "    for obj in response.get(\"Contents\", []):\n",
    "        if obj[\"Key\"] == key:\n",
    "            return obj[\"Size\"]\n",
    "        \n",
    "def _key_files__list(client, bucket, key):\n",
    "    \"\"\"return the key's size if it exist, else None\"\"\"\n",
    "    response = client.list_objects_v2(Bucket=bucket, Prefix=key)\n",
    "    return response.get(\"Contents\", [])\n",
    "\n",
    "def parquet_exists(s3_url):\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\"s3\")\n",
    "    bucket = s3_url.split(\"/\")[2]\n",
    "    key = s3_url.split(\"/\")[3:]\n",
    "    key = \"/\".join(key)+ \"/_SUCCESS\"\n",
    "    size = _key_existing_size__list(s3, bucket, key)\n",
    "    if size is not None:\n",
    "        print(\"File exists:\", s3_url)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_s3_parquets(s3_url):\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\"s3\")\n",
    "    bucket = s3_url.split(\"/\")[2]\n",
    "    key = s3_url.split(\"/\")[3:]\n",
    "    key = \"/\".join(key)\n",
    "    objects = _key_files__list(s3, bucket, key)\n",
    "    files = [\"s3://\" + bucket + \"/\" + file[\"Key\"][:-9] for file in objects if file[\"Key\"].split(\"/\")[-1]==\"_SUCCESS\"]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_url = 's3://data-bpop-dev-sandbox/estandarizado/productos/activo-tarjeta-credito-nueva'\n",
    "files = get_s3_parquets(s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, file in enumerate(files):\n",
    "    print('File:', file)\n",
    "    data_temp = spark_read_parquet(file)\n",
    "    if ix == 0:\n",
    "        data_act = data_temp\n",
    "    else:\n",
    "        data_act = pd.concat([data_act,data_temp], ignore_index=True)\n",
    "        \n",
    "    del data_temp       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act['fecha_activacion_plastico'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(data_act['fecha_activacion_plastico'][0])[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting variables\n",
    "data_act['fecha_activacion_plastico'] = pd.Series([str(x).replace('00','20') if '00' in str(x)[:2] else str(x) for x in data_act['fecha_activacion_plastico']])\n",
    "data_act['fecha_activacion_plastico'] = pd.to_datetime(data_act['fecha_activacion_plastico'], errors='coerce')\n",
    "data_act['mes_activacion'] = pd.to_datetime(data_act['fecha_activacion_plastico'].dt.strftime('%Y-%m'),format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renombrando variables\n",
    "data_act1.columns = data_act1.columns.str.lower()\n",
    "data_act1 = data_act1.rename(columns={'identificacion':'cedula'})\n",
    "data_act = data_act.rename(columns={'id_cli':'cedula',\n",
    "                                   'tipo_id_cliente':'tipo_identificacion',\n",
    "                                   'fecha_activacion_plastico':'fecha_activacion'})\n",
    "data_camp = data_camp.rename(columns={'NUM_DOC':'cedula'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act = data_act[['numero_cuenta', 'numero_tarjeta', 'cedula',\n",
    "       'tipo_identificacion', 'fecha_activacion', 'id_cliente',\n",
    "       'mes_activacion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniendo bases\n",
    "data_act = pd.concat([data_act1, data_act], ignore_index=True)\n",
    "data_act = data_act.drop_duplicates()\n",
    "\n",
    "del data_act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cast variables\n",
    "data_act['id_cliente'] = data_act['id_cliente'].fillna('-9999').astype(np.int64)\n",
    "data_act['tipo_identificacion'] = data_act['tipo_identificacion'].fillna('-9999').astype(np.int64)\n",
    "data_act['cedula'] = data_act['cedula'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_act.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_dates = ['2019-01', '2019-02','2019-03','2019-04','2019-05','2019-06','2019-07','2019-08','2019-09','2019-10','2019-11',\n",
    "          '2019-12','2020-01','2020-02','2020-03','2020-04','2020-05','2020-06','2020-07','2020-08','2020-09','2020-10',\n",
    "          '2020-11','2020-12','2021-01','2021-02','2021-03','2021-04','2021-05','2021-06','2021-07','2021-08', '2021-09',\n",
    "            '2021-10', '2021-11','2021-12','2022-01']\n",
    "date = str_dates[0]\n",
    "date = pd.to_datetime(date,format='%Y-%m')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "str_dates = ['2019-01', '2019-02','2019-03','2019-04','2019-05','2019-06','2019-07','2019-08','2019-09','2019-10','2019-11',\n",
    "          '2019-12','2020-01','2020-02','2020-03','2020-04','2020-05','2020-06','2020-07','2020-08','2020-09','2020-10',\n",
    "          '2020-11','2020-12','2021-01','2021-02','2021-03','2021-04','2021-05','2021-06','2021-07','2021-08', '2021-09',\n",
    "            '2021-10', '2021-11','2021-12','2022-01']\n",
    "\n",
    "n_mes = 3 # numero de meses\n",
    "\n",
    "for ix, date in enumerate(str_dates):\n",
    "    print('Fecha:',date)\n",
    "    date = pd.to_datetime(date,format='%Y-%m')\n",
    "    nom_col = 'camp_'+date.strftime('%Y%m')\n",
    "    \n",
    "    base = data_camp[data_camp['mes_campaña']==date]\n",
    "\n",
    "    if ix == 0:\n",
    "        base_final = func_activa(base,date,n_mes,nom_col)\n",
    "        del base\n",
    "    else:\n",
    "        base_temp = func_activa(base,date,n_mes,nom_col)\n",
    "        base_final = pd.concat([base_final,base_temp],ignore_index=True)\n",
    "        \n",
    "        del base, base_temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "n_mes=3\n",
    "date_fin = date + relativedelta(months=n_mes)\n",
    "date_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting variables\n",
    "base_final = base_final[base_final['cedula'].notnull()]\n",
    "\n",
    "#base_final.rename(columns={' CUPO_APROBADO ':'CUPO_APROBADO'}, inplace=True)\n",
    "#base_final['CUPO_APROBADO'] = base_final['CUPO_APROBADO'].str.strip()\n",
    "#base_final['CUPO_APROBADO'] = [str(x).replace('.','') for x in base_final['CUPO_APROBADO']]\n",
    "#base_final['CUPO_APROBADO'] = base_final['CUPO_APROBADO'].astype('float')\n",
    "\n",
    "cols = ['camp_201901','camp_201902','camp_201903','camp_201904','camp_201905','camp_201906',\n",
    "            'camp_201907','camp_201908','camp_201909','camp_201910','camp_201911','camp_201912',\n",
    "            'camp_202001','camp_202002','camp_202003','camp_202004','camp_202005','camp_202006',\n",
    "        'camp_202007','camp_202008','camp_202009','camp_202010','camp_202011','camp_202012',\n",
    "        'camp_202101','camp_202102','camp_202103','camp_202104','camp_202105','camp_202106','camp_202107',\n",
    "        'camp_202108', 'camp_202109', 'camp_202110', 'camp_202111', 'camp_202112', 'venta']\n",
    "                                                                              \n",
    "base_final.loc[:,cols] = base_final[cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting variables\n",
    "base_final['fecha_activacion'] = pd.to_datetime(base_final['fecha_activacion'], format='%Y-%m%d')\n",
    "base_final['mes_activacion'] = pd.to_datetime(base_final['mes_activacion'], format='%Y-%m%d')\n",
    "\n",
    "base_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de veces que ha sido incluido en la campaña últimos x meses\n",
    "# Número de meses desde que fue incluido en la campaña de adquisición por última vez\n",
    "# Número de activaciones de TC trad últimos x meses\n",
    "# Meses desde la última activación\n",
    "# Número de veces que ha sido incluido en la campaña y no aceptado\n",
    "# Si ya se ha aceptado anteriormente la oferta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['mes_campaña'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(base_final['mes_campaña'],base_final['venta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregando primer uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.Series(base_final['mes_campaña'].dt.strftime('%Y%m').unique().astype('int')).sort_values()\n",
    "\n",
    "i = 0\n",
    "for date in dates:\n",
    "    print(\"Fecha:\", date)\n",
    "    data_temp = trx_masterfile(date)\n",
    "    print(len(data_temp))\n",
    "    \n",
    "    if (len(data_temp) > 0):\n",
    "        if i == 0:\n",
    "            data_trx = data_temp.copy()\n",
    "            del data_temp\n",
    "            gc.collect()\n",
    "            i = i + 1\n",
    "        else:\n",
    "            data_trx = pd.concat([data_trx,data_temp],ignore_index=True)\n",
    "\n",
    "            del data_temp\n",
    "            gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_trx.shape)\n",
    "data_trx.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.reset_index([llave,'numero_cuenta'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining llave\n",
    "# cedula\n",
    "llave = 'cedula'\n",
    "## Defining index\n",
    "base_final.columns = base_final.columns.str.lower()\n",
    "base_final.set_index([llave,'numero_cuenta'], inplace=True)\n",
    "\n",
    "## Renaming variables\n",
    "data_trx.rename(columns={'identificacion_cliente':'cedula',\n",
    "                        'nro_cuenta':'numero_cuenta'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trx['cedula'] = data_trx['cedula'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dates = pd.Series(base_final.loc[base_final['venta'] == 1,'fecha_activacion'].unique()).sort_values()\n",
    "act_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_final.reset_index().dtypes)\n",
    "print(data_trx.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calculando primer uso\n",
    "\n",
    "for date in act_dates:\n",
    "    print('Fecha Activación:',date)\n",
    "    data_tx_temp = data_trx[data_trx['fecha_transaccion']>=date]\n",
    "    base_final.loc[(base_final['venta'] == 1) & (base_final['fecha_activacion'] == date),'fecha_transaccion'] = data_tx_temp.groupby([llave,'numero_cuenta'])['fecha_transaccion'].min()\n",
    "    del data_tx_temp\n",
    "\n",
    "## Calculando días primer uso\n",
    "base_final['dias_first_use'] = (base_final['fecha_transaccion'] - base_final['fecha_activacion'])/pd.offsets.Day(1)\n",
    "base_final['30first_use'] = np.where(base_final['dias_first_use']<=30,1,0)\n",
    "base_final.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['fecha_transaccion'].isnull().sum()/base_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['venta'] = base_final['venta'].fillna(0)\n",
    "###\n",
    "tabla_final = base_final.groupby(['cedula','tipo_camp','mes_campaña'])['venta','30first_use'].max().reset_index()\n",
    "tabla_final = tabla_final.rename(columns={'cedula':'id_numero_cliente'})\n",
    "tabla_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabla_final['30first_use'].value_counts()/tabla_final.shape[0])\n",
    "print(tabla_final.loc[tabla_final['venta']==1,'30first_use'].value_counts()/tabla_final[tabla_final['venta']==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardando Base:\n",
    "path_final = 's3://adl-refined-dev-popular/parquet/TC_adquisicion/base_VO_recalibración'\n",
    "\n",
    "tabla_final.to_parquet(path_final, engine = 'pyarrow', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando MDTS  ###(si se requiere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 's3://adl-refined-dev-popular/parquet/TC_adquisicion'\n",
    "\n",
    "objects = list_files(path)\n",
    "files = [path + '/' + file for file in objects if (\"total_tdc_M\" in file)]\n",
    "files = files[1:] # Se arranca desde abril\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, file in enumerate(files):\n",
    "    print(file)\n",
    "    if ix == 0:\n",
    "        base_mdt = spark_read_parquet(file)\n",
    "        base_mdt = base_mdt.rename(columns={'sum_tx_linea':'sum_tx_linea_pasv', 'sum_tx_nolinea':'sum_tx_nolinea_pasv'})\n",
    "        gc.collect()\n",
    "    else:\n",
    "        base_temp = spark_read_parquet(file)\n",
    "        base_temp = base_temp.rename(columns={'sum_tx_linea':'sum_tx_linea_pasv', 'sum_tx_nolinea':'sum_tx_nolinea_pasv'})\n",
    "        base_mdt = pd.concat([base_mdt,base_temp])\n",
    "        del base_temp\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_mdt.shape)\n",
    "base_mdt.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_finales = [\n",
    "'id_numero_cliente',\n",
    "'mes_campaña',\n",
    "'amortizacion_min_LB',#\n",
    "'cuota_max_LB_SMLV',#\n",
    "'dias_desde_ult_tx_ahr',#\n",
    "'num_lib_solicitadas',#\n",
    "'num_no_aceptado',#\n",
    "'num_tx_ult_1mes_ahr',#\n",
    "'numero_obligaciones_activasdif',#\n",
    "'pasv_antig_total',#\n",
    "'pasv_saldo_ca_1mes_atras',#\n",
    "'porcentaje_utilizacion',#\n",
    "'prom_monto_novado',#\n",
    "'prom_n_cuotas',#\n",
    "'quanto_mod',#\n",
    "'sum_tx_linea_ahr',#\n",
    "'valor_cuotas_codeudores_smlv',#\n",
    "'valor_utilizado_smlv',#\n",
    "]\n",
    "\n",
    "base_mdt = base_mdt.rename(columns = {'fecha_camp':'mes_campaña',\n",
    "                                      'amortizacion_min_lb':'amortizacion_min_LB',\n",
    "                                      'cuota_max_lb_smlv':'cuota_max_LB_SMLV'})\n",
    "base_mdt = base_mdt[var_finales]\n",
    "base_mdt['mes_campaña'] = pd.to_datetime(base_mdt['mes_campaña'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cargando Score:\n",
    "\n",
    "files = [\n",
    "'propension-tc_preaprob_M20210318.csv',\n",
    "'propension-tc_preaprob_M20210419.csv',\n",
    "'propension-tc_preaprob_M20210520.csv',\n",
    "'propension-tc_preaprob_M20210616.csv',\n",
    "'propension-tc_preaprob_M20210713.csv',\n",
    "'propension-tc_preaprob_M20210811.csv',\n",
    "'propension-tc_preaprob_M20210914.csv',\n",
    "'propension-tc_preaprob_M20211014.csv',\n",
    "'propension-tc_preaprob_M20211112.csv'\n",
    "]\n",
    "\n",
    "fechas = ['2021-04-01', '2021-05-01', '2021-06-01', '2021-07-01', '2021-08-01', '2021-09-01', '2021-10-01', '2021-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 's3://adl-refined-dev-popular/parquet/TC_adquisicion/'\n",
    "\n",
    "i = 0\n",
    "for file, date in zip(files, fechas):\n",
    "    if i == 0:\n",
    "        base_score = pd.read_csv(path+file, sep='|')\n",
    "        base_score['mes_campaña'] = date\n",
    "        base_score['id_numero_cliente'] = base_score['id_numero_cliente'].astype('int')\n",
    "        i = i+1\n",
    "    else:\n",
    "        base_temp = pd.read_csv(path+file, sep='|')\n",
    "        base_temp['mes_campaña'] = date\n",
    "        base_temp['id_numero_cliente'] = base_temp['id_numero_cliente'].astype('int')\n",
    "        base_score = pd.concat([base_score,base_temp])\n",
    "        \n",
    "        del base_temp\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['mes_campaña'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score['mes_campaña'] = pd.to_datetime(base_score['mes_campaña'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final = base_final.rename(columns={'cedula':'id_numero_cliente'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_final[base_final['mes_campaña']>'2021-03-01'].shape)  \n",
    "print(base_final.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final = base_final[(base_final['mes_campaña']>'2021-03-01') & (base_final['mes_campaña']<'2021-11-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_final = pd.merge(base_final[['id_numero_cliente', 'mes_campaña', 'tipo_camp', \n",
    "                                   'fecha_activacion', 'mes_activacion','venta',\n",
    "                                  'fecha_transaccion','30first_use']],\n",
    "                       base_score[['id_numero_cliente', 'mes_campaña', 'score', 'decil']], \n",
    "                       on=['id_numero_cliente', 'mes_campaña'], how='left')\n",
    "\n",
    "\n",
    "print(base_score.shape)\n",
    "print(base_final.shape)\n",
    "print(tabla_final.shape)\n",
    "\n",
    "tabla_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SI SE REQUIERE\n",
    "tabla_finalF = pd.merge(tabla_final,base_mdt, \n",
    "                       on=['id_numero_cliente', 'mes_campaña'], how='left')\n",
    "\n",
    "\n",
    "print(tabla_final.shape)\n",
    "print(base_mdt.shape)\n",
    "print(tabla_finalF.shape)\n",
    "\n",
    "tabla_finalF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_finalF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_finalF['30first_use'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardando base MDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo = '202111'\n",
    "path_final = 's3://adl-refined-dev-popular/parquet/TC_adquisicion/MDT_recalib_M'\n",
    "\n",
    "tabla_finalF.to_parquet(path_final+periodo, engine = 'pyarrow', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corriendo Backtesting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funcion para Backtesting\n",
    "\n",
    "def backtesting(data,var_probab,var_target,cant,cutoff):\n",
    "\n",
    "    dataframe = data.copy()\n",
    "    dataframe[var_probab] = round(dataframe[var_probab]*1000)\n",
    "\n",
    "    if np.isnan(cutoff).any():\n",
    "        dataframe['rangos'] = pd.qcut(dataframe[var_probab],cant,precision=0,duplicates='drop')\n",
    "    else:\n",
    "        dataframe['rangos'] = pd.cut(dataframe[var_probab],cutoff,precision=0,include_lowest=True)\n",
    "    \n",
    "    dataframe['target'] = dataframe[var_target]\n",
    "    \n",
    "    table = pd.DataFrame(dataframe[['rangos','target']].groupby('rangos').size())\n",
    "    table = table.sort_values(by ='rangos', ascending=True)\n",
    "    table.rename(columns={0: 'total cat'}, inplace=True)\n",
    "\n",
    "    table = table.join(dataframe[['rangos','target']].groupby(['rangos']).sum())\n",
    "    table.rename(columns={'target': 'var 1'}, inplace=True)\n",
    "    table['var 0'] = table['total cat'] - table['var 1']\n",
    "    \n",
    "    table.insert(loc=1, column='% total cat', value=round((table['total cat'] / dataframe.shape[0])*100,2))\n",
    "    table.insert(loc=2, column='total acum', value=table['% total cat'].cumsum())\n",
    "    \n",
    "    table.insert(loc=4, column='tasa var 1', value=round((table['var 1']/table['total cat'])*100,2))\n",
    "    table.insert(loc=6, column='tasa var 0', value=round((table['var 0']/table['total cat'])*100,2))\n",
    "    \n",
    "    table.insert(loc=5, column='var 1 acum', value=round((table['var 1'].cumsum()/table['var 1'].sum())*100,2))\n",
    "    table.insert(loc=8, column='var 0 acum', value=round((table['var 0'].cumsum()/table['var 0'].sum())*100,2))\n",
    "    \n",
    "    table['KS'] = round(abs(table['var 1 acum']-table['var 0 acum']),2)\n",
    "    \n",
    "    table['tasa var 0 acum'] = [round((table.iloc[0+i:len(table),table.columns.get_loc('var 0')].sum()/\n",
    "                                       table.iloc[0+i:len(table),table.columns.get_loc('total cat')].sum())*100,2) for i in range(0,len(table))]\n",
    "    \n",
    "    table['odds acum'] = [round((table.iloc[0+i:len(table),table.columns.get_loc('var 1')].sum()/\n",
    "                                 table.iloc[0+i:len(table),table.columns.get_loc('var 0')].sum()),2) for i in range(0,len(table))]\n",
    "    \n",
    "    table['odds'] = round(table['var 1']/table['var 0'],2)\n",
    "    \n",
    "    comp = pd.DataFrame([int(np.where(table.iloc[1+i,table.columns.get_loc('odds')]>= \\\n",
    "                                      table.iloc[0+i,table.columns.get_loc('odds')],0,1)) for i in range(0,len(table)-1)])\n",
    "    \n",
    "    table['quiebres'] = pd.concat([pd.DataFrame([0]),comp]).set_index(table.index)\n",
    "     \n",
    "    table = table.sort_values(by ='rangos', ascending=False)\n",
    "    \n",
    "    table.reset_index(inplace=True)\n",
    "    \n",
    "    last_row = pd.DataFrame(['total',\n",
    "                             table['total cat'].sum(),\n",
    "                             round(table['% total cat'].sum()),\n",
    "                             '',\n",
    "                             table['var 1'].sum(),\n",
    "                             round((table['var 1'].sum()/table['total cat'].sum())*100,2),\n",
    "                             '',\n",
    "                             table['var 0'].sum(),\n",
    "                             round((table['var 0'].sum()/table['total cat'].sum())*100,2),\n",
    "                             '',\n",
    "                             table['KS'].max(),\n",
    "                             '',\n",
    "                             '',\n",
    "                             round(table['var 1'].sum()/table['var 0'].sum(),2),\n",
    "                             table['quiebres'].sum()]).T\n",
    "    \n",
    "    last_row.columns = table.columns\n",
    "\n",
    "    table = table.append(last_row)\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(tabla_final['decil'],tabla_final['venta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tabla = backtesting(tabla_final,'score','venta',5,cutoff = np.nan)\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estabilidad\n",
    "tabla_final['decil_mod']=pd.qcut(tabla_final['score'].rank(method='first'),10, labels=False)\n",
    "pd.crosstab(tabla_final['decil'],tabla_final['mes_campaña'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(tabla_final, index='decil', columns=['mes_campaña','venta'], aggfunc='count')['FECHA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando Base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_final+periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
