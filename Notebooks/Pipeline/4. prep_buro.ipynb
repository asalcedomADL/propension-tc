{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero_obligaciones_activasdif\n",
    "# porcentaje_utilizacion\n",
    "# quanto_mod\n",
    "# valor_cuotas_codeudores_smlv\n",
    "# valor_utilizado_smlv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODULE: processing_buro\n",
    "This script extracts Bur贸 information from the Bur贸 file\n",
    "Steps:\n",
    "1. Get buro files\n",
    "2. Get the needed columns and rows from Buro file including the needed historical period\n",
    "3. Create additional columns\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def process_buro(input_path1, input_path2):\n",
    "    \"\"\"Using the input_paths for the last two buro files, this function puts everything together\"\"\"\n",
    "\n",
    "    # 1. Gets and appends the last two buro files\n",
    "    buro = get_buro_file(input_path1, input_path2)\n",
    "    print('get_buro_file')\n",
    "    # 2. Get the needed columns and rows from buro file including the needed historical period\n",
    "    buro = get_buro_info(buro)\n",
    "    print('get_buro_info')\n",
    "    # 3. Perform simple imputation to output data frame\n",
    "    buro_final = create_buro_df(buro)\n",
    "    print('create_buro_df')\n",
    "    print('buro_df created successfully')\n",
    "\n",
    "    return buro_final\n",
    "\n",
    "\n",
    "def get_buro_file(input_path1, input_path2):\n",
    "    \"\"\" Gets the input_paths of the last two the buro files, appends them and drops some not useful columns\n",
    "     and outputs a DataFrame\n",
    "    :param\n",
    "    input_path1: location of the oldest buro file\n",
    "    input path2: location of the most recent buro file\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    buro_1 = spark_read_parquet(input_path1)\n",
    "    buro_1.columns = buro_1.columns.str.lower()\n",
    "    buro_1 = buro_1.rename(columns={'cont_id': 'id_cliente'})\n",
    "\n",
    "    buro_1['marca_buro'] = 1\n",
    "    if buro_1['no_identificacion'].isnull().sum() > 0:\n",
    "        buro_1 = buro_1.loc[buro_1['no_identificacion'].notnull()]\n",
    "\n",
    "    buro_1['no_identificacion'] = buro_1['no_identificacion'].astype('str')\n",
    "    buro_1['no_identificacion'] = buro_1['no_identificacion'].astype(np.int64)\n",
    "\n",
    "    buro_2 = spark_read_parquet(input_path2)\n",
    "    buro_2.columns = buro_2.columns.str.lower()\n",
    "    buro_2 = buro_2.rename(columns={'cont_id': 'id_cliente'})\n",
    "\n",
    "    buro_2['marca_buro'] = 2\n",
    "    if buro_2['no_identificacion'].isnull().sum() > 0:\n",
    "        buro_2 = buro_2.loc[buro_2['no_identificacion'].notnull()]\n",
    "\n",
    "    buro_2['no_identificacion'] = buro_2['no_identificacion'].astype('str')\n",
    "    buro_2['no_identificacion'] = buro_2['no_identificacion'].astype(np.int64)\n",
    "\n",
    "    buro = pd.concat([buro_1,buro_2], ignore_index=True)\n",
    "    \n",
    "    if buro['no_identificacion'].isnull().sum() > 0:\n",
    "        buro = buro.loc[buro['no_identificacion'].notnull()]\n",
    "\n",
    "    buro['no_identificacion'] = buro['no_identificacion'].astype(np.int64)\n",
    "    buro['id_cliente'] = buro['id_cliente'].fillna('-999').astype(np.int64)\n",
    "    buro = buro[['tipo_id','tipo_id_homologado','no_identificacion', 'fecha_envio',\n",
    "                 'id_cliente', 'marca_buro', \n",
    "                 'numero_obligaciones_activas',\n",
    "                 'porcentaje_utilizacion',\n",
    "                 'quanto_mod',\n",
    "                 'valor_cupos',\n",
    "                 'valor_utilizado',\n",
    "                 'valor_cuotas_codeudores']]\n",
    "    \n",
    "    buro = buro.fillna(0)\n",
    "\n",
    "    return buro\n",
    "\n",
    "\n",
    "def get_buro_info(buro):\n",
    "    \"\"\"Deletes duplicates and casts dates\n",
    "    :param buro to buro file location\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    # casting dates\n",
    "    buro = buro[buro['fecha_envio'].notnull()]\n",
    "    buro['fecha_envio'] = buro['fecha_envio'].astype('str')\n",
    "    buro['fecha_buro'] = (\n",
    "                buro['fecha_envio'].str.replace('-', '').str[0:4] + buro['fecha_envio'].str.replace('-', '').str[\n",
    "                                                                    4:6]).astype('int')\n",
    "\n",
    "    # deleting duplicates\n",
    "    buro = buro.sort_values(['no_identificacion', 'fecha_buro'])\n",
    "    buro = buro.drop_duplicates(subset=['no_identificacion', 'fecha_buro'], keep='first')\n",
    "\n",
    "    return buro\n",
    "\n",
    "\n",
    "def create_buro_df(buro):\n",
    "    \"\"\"Creates client-level variables final variables\n",
    "    :param buro containing buro relevant rows and columns\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    # creating lag variables\n",
    "    buro['llave_lag'] = np.where(buro['no_identificacion'] == buro['no_identificacion'].shift(1), 1, 0)\n",
    "\n",
    "    # variable cupo mercado\n",
    "    buro['ano_po'] = buro['fecha_buro'].astype(str).str[0:4].astype(int)\n",
    "    buro['smlv'] = np.where(buro['ano_po'] == 2018, 781242,\n",
    "                            np.where(buro['ano_po'] == 2019, 828116,\n",
    "                                     np.where(buro['ano_po'] == 2020, 877803,\n",
    "                                              np.where(buro['ano_po'] == 2021, 908526,\n",
    "                                              np.nan))))\n",
    "    \n",
    "    if buro['porcentaje_utilizacion'].dtypes == 'object':\n",
    "        buro['porcentaje_utilizacion2'] = [float(str(x).replace('\"','').replace(',','.')) for x in buro['porcentaje_utilizacion']]\n",
    "        buro['porcentaje_utilizacion2'] = buro['porcentaje_utilizacion'].astype('float64')\n",
    "    \n",
    "    if (buro['porcentaje_utilizacion2'] > 0).sum()/buro.shape[0] < 0.7:\n",
    "        buro['porcentaje_utilizacion'] = np.where(buro['valor_cupos']>0, round(buro['valor_utilizado']/buro['valor_cupos'],9),buro['porcentaje_utilizacion2'])\n",
    "\n",
    "    buro['valor_cuotas_codeudores_smlv']= buro['valor_cuotas_codeudores']/buro['smlv']\n",
    "    buro['valor_utilizado_smlv']= buro['valor_utilizado']/buro['smlv']\n",
    "    \n",
    "    var = 'numero_obligaciones_activas'\n",
    " \n",
    "    # creating lag variables lag\n",
    "    buro['llave_lag'] = np.where(buro['no_identificacion'] == buro['no_identificacion'].shift(1), 1, 0)\n",
    "\n",
    "    buro[var+'lag1']=np.where(buro['llave_lag']==1,buro[var].shift(1),np.nan)\n",
    "    buro[var+'dif']=np.where( ((np.isnan(buro[var])) | (buro[var]==0)) & ((np.isnan(buro[var+'lag1'])) | (buro[var+'lag1']==0)) ,0,\n",
    "                              np.where( ((np.isnan(buro[var])) | (buro[var]==0)) & ((buro[var+'lag1']>0)) ,-1,\n",
    "                              np.where( ((np.isnan(buro[var+'lag1'])) | (buro[var+'lag1']==0)) & ((buro[var]>0)) ,1,\n",
    "                              np.where( (buro[var+'lag1']>0) & (buro[var]>0) , (buro[var]-buro[var+'lag1'])/buro[var+'lag1'],99))))\n",
    "    \n",
    "    del buro[var+'lag1'], var\n",
    "    \n",
    "    #Last filter\n",
    "    buro = buro[buro['marca_buro'] == 2]\n",
    "    \n",
    "    buro_out = buro[['tipo_id','tipo_id_homologado','no_identificacion','id_cliente', 'fecha_buro', \n",
    "                     'numero_obligaciones_activasdif',\n",
    "                    'porcentaje_utilizacion',\n",
    "                    'quanto_mod',\n",
    "                    'valor_cuotas_codeudores_smlv',\n",
    "                    'valor_utilizado_smlv']]\n",
    "\n",
    "    return buro_out\n",
    "\n",
    "def spark_read_parquet(s3_url: str, **args):\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    # Leyendo base\n",
    "    dataset = pq.ParquetDataset(s3_url, filesystem=fs)\n",
    "    table = dataset.read()\n",
    "    dataframe = table.to_pandas()\n",
    "\n",
    "    del dataset, table\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import boto3.session\n",
    "\n",
    "def _key_existing_size__list(client, bucket, key):\n",
    "    \"\"\"return the key's size if it exist, else None\"\"\"\n",
    "    response = client.list_objects_v2(Bucket=bucket, Prefix=key)\n",
    "    for obj in response.get(\"Contents\", []):\n",
    "        if obj[\"Key\"] == key:\n",
    "            return obj[\"Size\"]\n",
    "        \n",
    "def _key_files__list(client, bucket, key):\n",
    "    \"\"\"return the key's size if it exist, else None\"\"\"\n",
    "    response = client.list_objects_v2(Bucket=bucket, Prefix=key)\n",
    "    return response.get(\"Contents\", [])\n",
    "\n",
    "def parquet_exists(s3_url):\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\"s3\")\n",
    "    bucket = s3_url.split(\"/\")[2]\n",
    "    key = s3_url.split(\"/\")[3:]\n",
    "    key = \"/\".join(key)+ \"/_SUCCESS\"\n",
    "    size = _key_existing_size__list(s3, bucket, key)\n",
    "    if size is not None:\n",
    "        print(\"File exists:\", s3_url)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_s3_parquets(s3_url):\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\"s3\")\n",
    "    bucket = s3_url.split(\"/\")[2]\n",
    "    key = s3_url.split(\"/\")[3:]\n",
    "    key = \"/\".join(key)\n",
    "    objects = _key_files__list(s3, bucket, key)\n",
    "    files = [\"s3://\" + bucket + \"/\" + file[\"Key\"][:-9] for file in objects if file[\"Key\"].split(\"/\")[-1]==\"_SUCCESS\"]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M201811',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M201905',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M201908',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M201911',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M202003',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M202006',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M202009',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M202012',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M202103',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M202106',\n",
       " 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero/riesgos-creditos_buro-comportamiento-financiero_experian_M202109']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_url = 's3://data-bpop-dev-sandbox/estandarizado/riesgos-creditos/buro-comportamiento-financiero'\n",
    "files = get_s3_parquets(s3_url)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_buro_file\n",
      "get_buro_info\n",
      "create_buro_df\n",
      "buro_df created successfully\n"
     ]
    }
   ],
   "source": [
    "input_path1 = files[-1]\n",
    "input_path2 = files[-2]\n",
    "\n",
    "\n",
    "buro_mdt = process_buro(input_path2, input_path1)\n",
    "#buro_mdt = get_buro_file(input_path2, input_path1)\n",
    "#buro_mdt = get_buro_info(buro_mdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_id</th>\n",
       "      <th>tipo_id_homologado</th>\n",
       "      <th>no_identificacion</th>\n",
       "      <th>id_cliente</th>\n",
       "      <th>fecha_buro</th>\n",
       "      <th>numero_obligaciones_activasdif</th>\n",
       "      <th>porcentaje_utilizacion</th>\n",
       "      <th>quanto_mod</th>\n",
       "      <th>valor_cuotas_codeudores_smlv</th>\n",
       "      <th>valor_utilizado_smlv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>701386</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>206</td>\n",
       "      <td>421952294130855802</td>\n",
       "      <td>202110</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3806000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605345</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>1112</td>\n",
       "      <td>543052294130923801</td>\n",
       "      <td>202110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1735000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699705</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>1974</td>\n",
       "      <td>243652294131526401</td>\n",
       "      <td>202110</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>9530000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728330</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>2245</td>\n",
       "      <td>303052294131744902</td>\n",
       "      <td>202110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2471000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719650</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>2460</td>\n",
       "      <td>248852294131623002</td>\n",
       "      <td>202110</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5714000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tipo_id tipo_id_homologado  no_identificacion          id_cliente  \\\n",
       "701386       1            1000003                206  421952294130855802   \n",
       "605345       1            1000003               1112  543052294130923801   \n",
       "699705       1            1000003               1974  243652294131526401   \n",
       "728330       1            1000003               2245  303052294131744902   \n",
       "719650       1            1000003               2460  248852294131623002   \n",
       "\n",
       "        fecha_buro  numero_obligaciones_activasdif  porcentaje_utilizacion  \\\n",
       "701386      202110                       -0.200000                0.000000   \n",
       "605345      202110                        0.000000                0.000000   \n",
       "699705      202110                       -0.076923                0.002421   \n",
       "728330      202110                        0.000000                0.000000   \n",
       "719650      202110                       -0.200000                0.000000   \n",
       "\n",
       "        quanto_mod  valor_cuotas_codeudores_smlv  valor_utilizado_smlv  \n",
       "701386   3806000.0                           0.0              0.000000  \n",
       "605345   1735000.0                           0.0              0.000000  \n",
       "699705   9530000.0                           0.0              0.186016  \n",
       "728330   2471000.0                           0.0              0.000000  \n",
       "719650   5714000.0                           0.0              0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buro_mdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo_id</th>\n",
       "      <th>tipo_id_homologado</th>\n",
       "      <th>no_identificacion</th>\n",
       "      <th>id_cliente</th>\n",
       "      <th>fecha_buro</th>\n",
       "      <th>numero_obligaciones_activasdif</th>\n",
       "      <th>porcentaje_utilizacion</th>\n",
       "      <th>quanto_mod</th>\n",
       "      <th>valor_cuotas_codeudores_smlv</th>\n",
       "      <th>valor_utilizado_smlv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603519</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>1235254689</td>\n",
       "      <td>543460626072472806</td>\n",
       "      <td>202110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.984524</td>\n",
       "      <td>1489000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.910266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626970</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>1235257401</td>\n",
       "      <td>273259232272927502</td>\n",
       "      <td>202110</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.655758</td>\n",
       "      <td>1671000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.190940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603520</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>1235538413</td>\n",
       "      <td>689353298356223902</td>\n",
       "      <td>202110</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2216000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626841</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>1236238430</td>\n",
       "      <td>265662878988485706</td>\n",
       "      <td>202110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1762000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.343935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686099</th>\n",
       "      <td>1</td>\n",
       "      <td>1000003</td>\n",
       "      <td>2000001262</td>\n",
       "      <td>428462819218377311</td>\n",
       "      <td>202110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896125</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.468834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tipo_id tipo_id_homologado  no_identificacion          id_cliente  \\\n",
       "603519       1            1000003         1235254689  543460626072472806   \n",
       "626970       1            1000003         1235257401  273259232272927502   \n",
       "603520       1            1000003         1235538413  689353298356223902   \n",
       "626841       1            1000003         1236238430  265662878988485706   \n",
       "686099       1            1000003         2000001262  428462819218377311   \n",
       "\n",
       "        fecha_buro  numero_obligaciones_activasdif  porcentaje_utilizacion  \\\n",
       "603519      202110                        0.000000                0.984524   \n",
       "626970      202110                        0.333333                0.655758   \n",
       "603520      202110                        0.200000                0.000000   \n",
       "626841      202110                        1.000000                1.110000   \n",
       "686099      202110                        0.000000                0.896125   \n",
       "\n",
       "        quanto_mod  valor_cuotas_codeudores_smlv  valor_utilizado_smlv  \n",
       "603519   1489000.0                           0.0              0.910266  \n",
       "626970   1671000.0                           0.0              1.190940  \n",
       "603520   2216000.0                           0.0              0.000000  \n",
       "626841   1762000.0                           0.0              1.343935  \n",
       "686099   1480000.0                           0.0              2.468834  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buro_mdt.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tipo_id                            object\n",
       "tipo_id_homologado                 object\n",
       "no_identificacion                   int64\n",
       "id_cliente                          int64\n",
       "fecha_buro                          int64\n",
       "numero_obligaciones_activasdif    float64\n",
       "porcentaje_utilizacion            float64\n",
       "quanto_mod                        float64\n",
       "valor_cuotas_codeudores_smlv      float64\n",
       "valor_utilizado_smlv              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buro_mdt.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardando Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodo = '202112'\n",
    "path_out = 's3://adl-refined-dev-popular/parquet/TC_adquisicion/base_buro_M'\n",
    "file_name_out = path_out + periodo\n",
    "buro_mdt.to_parquet(file_name_out,engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://adl-refined-dev-popular/parquet/TC_adquisicion/base_buro_M202112'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aaaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7bae8076a577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maaaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aaaa' is not defined"
     ]
    }
   ],
   "source": [
    "aaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODULE: processing_buro\n",
    "This script extracts Bur贸 information from the Bur贸 file\n",
    "Steps:\n",
    "1. Get buro files\n",
    "2. Get the needed columns and rows from Buro file including the needed historical period\n",
    "3. Create additional columns\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def process_buro(input_path1, input_path2):\n",
    "    \"\"\"Using the input_paths for the last two buro files, this function puts everything together\"\"\"\n",
    "\n",
    "    # 1. Gets and appends the last two buro files\n",
    "    buro = get_buro_file(input_path1, input_path2)\n",
    "    print('get_buro_file')\n",
    "    # 2. Get the needed columns and rows from buro file including the needed historical period\n",
    "    buro = get_buro_info(buro)\n",
    "    print('get_buro_info')\n",
    "    # 3. Perform simple imputation to output data frame\n",
    "    buro_final = create_buro_df(buro)\n",
    "    print('create_buro_df')\n",
    "    print('buro_df created successfully')\n",
    "\n",
    "    return buro_final\n",
    "\n",
    "\n",
    "def get_buro_file(input_path1, input_path2):\n",
    "    \"\"\" Gets the input_paths of the last two the buro files, appends them and drops some not useful columns\n",
    "     and outputs a DataFrame\n",
    "    :param\n",
    "    input_path1: location of the oldest buro file\n",
    "    input path2: location of the most recent buro file\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    buro_1 = spark_read_parquet(input_path1)\n",
    "    buro_1.columns = buro_1.columns.str.lower()\n",
    "    buro_1 = buro_1.rename(columns={'cont_id': 'id_cliente'})\n",
    "\n",
    "    buro_1['marca_buro'] = 1\n",
    "    if buro_1['no_identificacion'].isnull().sum() > 0:\n",
    "        buro_1 = buro_1.loc[buro_1['no_identificacion'].notnull()]\n",
    "\n",
    "    buro_1['no_identificacion'] = buro_1['no_identificacion'].astype('str')\n",
    "    buro_1['no_identificacion'] = buro_1['no_identificacion'].astype(np.int64)\n",
    "\n",
    "    buro_2 = spark_read_parquet(input_path2)\n",
    "    buro_2.columns = buro_2.columns.str.lower()\n",
    "    buro_2 = buro_2.rename(columns={'cont_id': 'id_cliente'})\n",
    "\n",
    "    buro_2['marca_buro'] = 2\n",
    "    if buro_2['no_identificacion'].isnull().sum() > 0:\n",
    "        buro_2 = buro_2.loc[buro_2['no_identificacion'].notnull()]\n",
    "\n",
    "    buro_2['no_identificacion'] = buro_2['no_identificacion'].astype('str')\n",
    "    buro_2['no_identificacion'] = buro_2['no_identificacion'].astype(np.int64)\n",
    "\n",
    "    buro = pd.concat([buro_1,buro_2], ignore_index=True)\n",
    "    \n",
    "    if buro['no_identificacion'].isnull().sum() > 0:\n",
    "        buro = buro.loc[buro['no_identificacion'].notnull()]\n",
    "\n",
    "    buro['no_identificacion'] = buro['no_identificacion'].astype(np.int64)\n",
    "    buro['id_cliente'] = buro['id_cliente'].fillna('-999').astype(np.int64)\n",
    "    buro = buro[['tipo_id','tipo_id_homologado','no_identificacion', 'fecha_envio',\n",
    "                 'id_cliente', 'marca_buro', \n",
    "                 'numero_obligaciones_activas',\n",
    "                 'porcentaje_utilizacion',\n",
    "                 'quanto_mod',\n",
    "                 'valor_cupos',\n",
    "                 'valor_utilizado',\n",
    "                 'valor_cuotas_codeudores']]\n",
    "    \n",
    "    buro = buro.fillna(0)\n",
    "\n",
    "    return buro\n",
    "\n",
    "\n",
    "def get_buro_info(buro):\n",
    "    \"\"\"Deletes duplicates and casts dates\n",
    "    :param buro to buro file location\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    # casting dates\n",
    "    buro = buro[buro['fecha_envio'].notnull()]\n",
    "    buro['fecha_envio'] = buro['fecha_envio'].astype('str')\n",
    "    buro['fecha_buro'] = (\n",
    "                buro['fecha_envio'].str.replace('-', '').str[0:4] + buro['fecha_envio'].str.replace('-', '').str[\n",
    "                                                                    4:6]).astype('int')\n",
    "\n",
    "    # deleting duplicates\n",
    "    buro = buro.sort_values(['no_identificacion', 'fecha_buro'])\n",
    "    buro = buro.drop_duplicates(subset=['no_identificacion', 'fecha_buro'], keep='first')\n",
    "\n",
    "    return buro\n",
    "\n",
    "\n",
    "def create_buro_df(buro):\n",
    "    \"\"\"Creates client-level variables final variables\n",
    "    :param buro containing buro relevant rows and columns\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    # creating lag variables\n",
    "    buro['llave_lag'] = np.where(buro['no_identificacion'] == buro['no_identificacion'].shift(1), 1, 0)\n",
    "\n",
    "    # variable cupo mercado\n",
    "    buro['ano_po'] = buro['fecha_buro'].astype(str).str[0:4].astype(int)\n",
    "    buro['smlv'] = np.where(buro['ano_po'] == 2018, 781242,\n",
    "                            np.where(buro['ano_po'] == 2019, 828116,\n",
    "                                     np.where(buro['ano_po'] == 2020, 877803,\n",
    "                                              np.where(buro['ano_po'] == 2021, 908526,\n",
    "                                              np.nan))))\n",
    "    \n",
    "    if (buro['porcentaje_utilizacion'] > 0).sum()/buro.shape[0] > 0.9:\n",
    "    \n",
    "        buro['porcentaje_utilizacion'] = [float(str(x).replace('\"','').replace(',','.')) for x in buro['porcentaje_utilizacion']]\n",
    "        buro['porcentaje_utilizacion'] = buro['porcentaje_utilizacion'].astype('float')\n",
    "    else:\n",
    "        buro['porcentaje_utilizacion'] = np.where(buro['valor_cupos']>0, round(buro['valor_utilizado']/buro['valor_cupos'],4),0) \n",
    "\n",
    "\n",
    "    buro['valor_cuotas_codeudores_smlv']= buro['valor_cuotas_codeudores']/buro['smlv']\n",
    "    buro['valor_utilizado_smlv']= buro['valor_utilizado']/buro['smlv']\n",
    "    \n",
    "    var = 'numero_obligaciones_activas'\n",
    " \n",
    "    # creating lag variables lag\n",
    "    buro['llave_lag'] = np.where(buro['no_identificacion'] == buro['no_identificacion'].shift(1), 1, 0)\n",
    "\n",
    "    buro[var+'lag1']=np.where(buro['llave_lag']==1,buro[var].shift(1),np.nan)\n",
    "    buro[var+'dif']=np.where( ((np.isnan(buro[var])) | (buro[var]==0)) & ((np.isnan(buro[var+'lag1'])) | (buro[var+'lag1']==0)) ,0,\n",
    "                              np.where( ((np.isnan(buro[var])) | (buro[var]==0)) & ((buro[var+'lag1']>0)) ,-1,\n",
    "                              np.where( ((np.isnan(buro[var+'lag1'])) | (buro[var+'lag1']==0)) & ((buro[var]>0)) ,1,\n",
    "                              np.where( (buro[var+'lag1']>0) & (buro[var]>0) , (buro[var]-buro[var+'lag1'])/buro[var+'lag1'],99))))\n",
    "    \n",
    "    del buro[var+'lag1'], var\n",
    "    \n",
    "    #Last filter\n",
    "    buro = buro[buro['marca_buro'] == 2]\n",
    "    \n",
    "    buro_out = buro[['tipo_id','tipo_id_homologado','no_identificacion','id_cliente', 'fecha_buro', \n",
    "                     'numero_obligaciones_activasdif',\n",
    "                    'porcentaje_utilizacion',\n",
    "                    'quanto_mod',\n",
    "                    'valor_cuotas_codeudores_smlv',\n",
    "                    'valor_utilizado_smlv']]\n",
    "\n",
    "    return buro_out\n",
    "\n",
    "def spark_read_parquet(s3_url: str, **args):\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    # Leyendo base\n",
    "    dataset = pq.ParquetDataset(s3_url, filesystem=fs)\n",
    "    table = dataset.read()\n",
    "    dataframe = table.to_pandas()\n",
    "\n",
    "    del dataset, table\n",
    "\n",
    "    return dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
